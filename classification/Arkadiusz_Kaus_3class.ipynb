{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('classification_problem.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>983.990540</td>\n",
       "      <td>942.286499</td>\n",
       "      <td>661.727966</td>\n",
       "      <td>943.103271</td>\n",
       "      <td>862.790222</td>\n",
       "      <td>105.079277</td>\n",
       "      <td>-4.460563</td>\n",
       "      <td>899.619080</td>\n",
       "      <td>198.236786</td>\n",
       "      <td>372.159210</td>\n",
       "      <td>721.331665</td>\n",
       "      <td>573.659851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>977.899475</td>\n",
       "      <td>943.009949</td>\n",
       "      <td>660.280029</td>\n",
       "      <td>953.870422</td>\n",
       "      <td>865.226379</td>\n",
       "      <td>106.982498</td>\n",
       "      <td>1.351808</td>\n",
       "      <td>903.402222</td>\n",
       "      <td>204.626221</td>\n",
       "      <td>358.535583</td>\n",
       "      <td>717.090576</td>\n",
       "      <td>515.002991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>997.377319</td>\n",
       "      <td>943.708069</td>\n",
       "      <td>663.513123</td>\n",
       "      <td>929.276184</td>\n",
       "      <td>861.283142</td>\n",
       "      <td>113.385300</td>\n",
       "      <td>9.707563</td>\n",
       "      <td>906.708252</td>\n",
       "      <td>204.998215</td>\n",
       "      <td>349.990387</td>\n",
       "      <td>668.513977</td>\n",
       "      <td>501.894470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001.554688</td>\n",
       "      <td>944.264709</td>\n",
       "      <td>650.176453</td>\n",
       "      <td>909.029968</td>\n",
       "      <td>861.296997</td>\n",
       "      <td>110.551079</td>\n",
       "      <td>-5.713619</td>\n",
       "      <td>911.538940</td>\n",
       "      <td>203.693878</td>\n",
       "      <td>349.119629</td>\n",
       "      <td>724.664612</td>\n",
       "      <td>571.145813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1007.083252</td>\n",
       "      <td>943.864685</td>\n",
       "      <td>662.991455</td>\n",
       "      <td>931.140503</td>\n",
       "      <td>858.884033</td>\n",
       "      <td>108.564102</td>\n",
       "      <td>-6.160424</td>\n",
       "      <td>903.476929</td>\n",
       "      <td>195.064453</td>\n",
       "      <td>367.321808</td>\n",
       "      <td>680.104126</td>\n",
       "      <td>540.926025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1           2           3           4           5   \\\n",
       "0   983.990540  942.286499  661.727966  943.103271  862.790222  105.079277   \n",
       "1   977.899475  943.009949  660.280029  953.870422  865.226379  106.982498   \n",
       "2   997.377319  943.708069  663.513123  929.276184  861.283142  113.385300   \n",
       "3  1001.554688  944.264709  650.176453  909.029968  861.296997  110.551079   \n",
       "4  1007.083252  943.864685  662.991455  931.140503  858.884033  108.564102   \n",
       "\n",
       "         6           7           8           9           10          11  \n",
       "0 -4.460563  899.619080  198.236786  372.159210  721.331665  573.659851  \n",
       "1  1.351808  903.402222  204.626221  358.535583  717.090576  515.002991  \n",
       "2  9.707563  906.708252  204.998215  349.990387  668.513977  501.894470  \n",
       "3 -5.713619  911.538940  203.693878  349.119629  724.664612  571.145813  \n",
       "4 -6.160424  903.476929  195.064453  367.321808  680.104126  540.926025  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.full(1000, 0)\n",
    "y = np.append(y, np.full(1000, 1))\n",
    "y = np.append(y, np.full(1000, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "      <th>class_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class_0  class_1  class_2\n",
       "0           1        0        0\n",
       "1           1        0        0\n",
       "2           1        0        0\n",
       "3           1        0        0\n",
       "4           1        0        0\n",
       "...       ...      ...      ...\n",
       "2995        0        0        1\n",
       "2996        0        0        1\n",
       "2997        0        0        1\n",
       "2998        0        0        1\n",
       "2999        0        0        1\n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(y, prefix='class')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X.values)\n",
    "y_train = torch.tensor(y.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "n_features = len(X_train[0])\n",
    "n_classes = len(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classificator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classificator, self).__init__()\n",
    "        self.batch_norm1 = torch.nn.BatchNorm1d(n_features)\n",
    "        self.linear1 = torch.nn.Linear(n_features, 128)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.dropout1 = torch.nn.Dropout(0.3)\n",
    "        \n",
    "        self.linear2 = torch.nn.Linear(128, 64)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.dropout2 = torch.nn.Dropout(0.3)\n",
    "        \n",
    "        self.linear3 = torch.nn.Linear(64, n_classes)\n",
    "        self.softmax1 = torch.nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.linear3(x)\n",
    "        x = self.softmax1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classificator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x28bb70d8e80>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]<ipython-input-106-5eaba1f1413d>:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax1(x)\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                         | 49/100 [00:12<00:11,  4.25it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "    for features, target in loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(features)\n",
    "        loss = loss_func(pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "print(f'Training finished!')\n",
    "print(f'loss = {loss.item()}')\n",
    "    #if epoch%10 == 0:\n",
    "        #print(f'epoch {epoch}, loss = {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(torch.nn.BatchNorm1d(12),\n",
    "                            torch.nn.Linear(len(X_train[0]), 128),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Dropout(0.3),\n",
    "                            torch.nn.Linear(128, 64),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Dropout(0.3),\n",
    "                            torch.nn.Linear(64, 3),\n",
    "                            torch.nn.Softmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):    \n",
    "    for features, target in loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(features)\n",
    "        loss = loss_func(pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch%10 == 0:\n",
    "        print(f'epoch {epoch}, loss = {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss = 0.22645479440689087\n",
      "epoch 10, loss = 0.2278936505317688\n",
      "epoch 20, loss = 0.22070561349391937\n",
      "epoch 30, loss = 0.21938972175121307\n",
      "epoch 40, loss = 0.2184659242630005\n",
      "epoch 50, loss = 0.21172857284545898\n",
      "epoch 60, loss = 0.207879900932312\n",
      "epoch 70, loss = 0.19956517219543457\n",
      "epoch 80, loss = 0.177198588848114\n",
      "epoch 90, loss = 0.17625707387924194\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):    \n",
    "    for features, target in loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(features)\n",
    "        loss = loss_func(pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch%10 == 0:\n",
    "        print(f'epoch {epoch}, loss = {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
